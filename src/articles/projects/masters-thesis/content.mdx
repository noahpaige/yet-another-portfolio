---
title: "Masters Thesis"
description: "Academic research and thesis work"
type: "project"
date: "2024-12-01"
readTime: 20
tags:
  [
    "Unity",
    "Game Development",
    "Research",
    "Academic",
    "Thesis",
    "AI",
    "Psychology",
    "Procedural Animation",
  ]
image: "/masters-thesis.png"
imageAltText: "Masters thesis research and academic work"
featured: true
featuredOrder: 1
colorPairs:
  [
    [{ h: 15, s: 70, l: 20 }, { h: 235, s: 5, l: 8 }],
    [{ h: 25, s: 60, l: 10 }, { h: 235, s: 10, l: 8 }],
  ]
seo:
  title: "Masters Thesis: AI-Driven NPC Behavior Using Psychological Models"
  description: "Academic research on integrating Five-Factor Model and Circumplex Model of Affect for more believable NPCs in video games"
  keywords:
    [
      "game AI",
      "NPC behavior",
      "psychological models",
      "procedural animation",
      "Unity",
      "academic research",
      "Five-Factor Model",
      "Circumplex Model",
    ]
  image: "/masters-thesis.png"
---

I completed this project in 2020 as part of my Masters in Computer Science at California Polytechnic State University, San Luis Obispo. You can download a full copy of my thesis [here](/Noah_Paige_Masters_Thesis.pdf). It's also available on [Cal Poly Digital Commons](https://digitalcommons.calpoly.edu/theses/2406/).

If you're lazy, check out the [TL;DR](#tldr).

For my visual learners, take a look at the [Video Showcase](#video-showcase).

For everyone else, go on down to the [Thesis Summary](#thesis-summary).

#### Key Achievements

- **Published Research**: Thesis available on [Cal Poly Digital Commons](https://digitalcommons.calpoly.edu/theses/2406/)
- **Technical Innovation**: Novel integration of psychology models with game AI
- **Statistical Validation**: 100 simulation iterations with correlation analysis
- **Real-time Systems**: Procedural animation with mood-driven facial expressions
- **Cross-disciplinary**: Applied psychological research to computer science

#### Technical Skills Demonstrated

- **Game Development**: Unity, C#, procedural animation, behavior systems
- **AI/ML**: Behavior modeling, decision trees, finite state machines, personality systems, mood simulation
- **Research**: Statistical analysis, correlation studies, academic writing
- **Psychology**: Five-Factor Model, Circumplex Model of Affect
- **Data Visualization**: Mood graphs, correlation tables, UI design, real-time feedback

---

## TL;DR

How do you make NPCs in video games feel more lifelike and believable? No, the answer is not to use an LLM! For one, I did this in the dark ages before ChatGPT. But more importantly, it’s the wrong tool. Instead, I turned to real psychology research: things like the [**Five-Factor Model of Personality**](#five-factor-model-of-personality) and the [Circumplex Model of Affect](#circumplex-model-of-affect). With these concepts, I built a system that gives NPCs actual personality traits and emotional states. Think of it as giving them a brain that’s not necessarily smarter, but more emotional. They get happy, they get grumpy, they make friends, and they avoid people they don't like.

These traits drive not just their decisions but also their facial expressions. As they make choices, their emotions show up on their faces in real time with procedural animation based on their mood. No more dead-eyed robots doing the same thing over and over. Their feelings affect their behavior, and their behavior changes how they feel. It’s a loop with emotional consequences.

To test the system, I built a simple maze environment in Unity. For each NPC, the goal was simple: reach the end of the maze. The way they went about solving it was completely up to them. Each one behaved differently depending on their personality, and even small tweaks in group dynamics led to different outcomes—who finished first, who helped or avoided others, and so on.

In testing, the system produced NPCs whose personalities and moods led to distinct, believable behaviors and expressive, emotionally-driven interactions — demonstrating that this approach can make game worlds feel more alive. While this work was constrained by the time and resources available to me as a student researcher, I love to imagine how this could be expanded upon with a larger team and more resources. Picture an innkeeper in Elder Scrolls who remembers you stole all of his things the last time you visited, or teammates in NBA 2K who act differently when you hog the ball.

---

## Video Showcase

#### Thesis Defense Presentation

This is a screen recording of the presentation I gave when I defended my thesis. If you want me to upload a version with audio, help me get 500 likes on the video!

<YouTubeVideo
  videoId="cK4MgCyOVPQ?si=PMUNEr0Zzjr_OEdV"
  title="Masters Thesis Presentation"
  maxHeight={300}
  horizontalAlign="center"
/>

<br />

#### Maze Simulation

Here's a video of the maze simulation from start to finish

<YouTubeVideo
  videoId="20RuUF9LnNA?si=bPFH-DJ0spAlYtrN"
  title="Maze Simulation Run"
  aspectRatio="1920:1000"
  maxHeight={300}
  horizontalAlign="center"
/>

---

# Thesis Summary

<br />

### Introduction

Non-player characters (NPCs) are a staple in most modern games, yet they are often criticized for their lack of believability and emotional realism. This thesis tackles that problem by proposing a behavior model for NPCs that integrates psychological models—specifically, the [**Five-Factor Model of Personality**](#five-factor-model-of-personality) and the [**Circumplex Model of Affect**](#circumplex-model-of-affect)—to create more dynamic and emotionally responsive NPCs.

The goal was to explore how personality and mood can be combined to produce emergent, unscripted behaviors in NPCs, which could enhance player immersion and narrative depth. To test the system, a maze simulation environment was built in Unity, where NPCs would navigate and interact based on their personalities and emotional states.

<br />

### Background

#### Role of NPCs in Games

NPCs play various roles in games—quest-givers, enemies, companions, or vendors. Yet many behave in limited, rigid ways due to reliance on traditional **finite state machines**, which lack flexibility in unpredictable situations. This leads to behavior that feels artificial and breaks immersion.

#### Five-Factor Model of Personality

Often referred to as the “Big Five,” this model breaks personality into five traits: **Openness**, **Conscientiousness**, **Extraversion**, **Agreeableness**, and **Neuroticism**. This forms the basis of the personality model used in this thesis.

<Image
  src="/five-factor-model.png"
  alt="Five-Factor Model of Personality Image"
  width={500}
  captionText="The Five-Factor Model of Personality, with examples of traits for low and high scores."
/>

#### Circumplex Model of Affect

This 2D model places emotions on a graph with axes for **pleasantness** and **activation** (energy). NPCs’ current moods are represented as points on this graph, which shift over time based on their experiences. The direction and magnitude of the shift is determined by a combination of the NPC's personality and the actions they take.

<Image
  src="/circumplex_model.png"
  alt="Circumplex Model of Affect Image"
  width={500}
  captionText="Russell’s Circumplex Model of Affect"
/>

#### Procedural Animation

Instead of using pre-recorded animations, this system uses **blendshapes**—facial expressions generated algorithmically based on mood. This approach saves time and produces more varied, reactive NPCs.

<br />

### Proposed Method

Three main components were developed:

1. **A behavior model** driven by personality and mood.
2. **A procedural facial animation system** that reflects NPC mood.
3. **A maze simulation** to observe emergent behaviors and interactions.

#### Behavior Model

NPCs are given a personality, which is a set of five numerical values for the five personality traits. Each NPC is assigned a numerical value (0–1) for each trait, which combine to define their personality. These values are used to determine the NPC's desired mood, which is a point on the Circumplex Model of Affect. Each action an NPC decides to take is assigned a potential value, which is a measure of how close it brings the NPC to their desired mood. The NPC then chooses the action with the highest potential value.

<Image
  src="/npc-flowchart.png"
  alt="Flowchart of a behavior update cycle"
  width={300}
  captionText="The flowchart describing a single update cycle of the behavior controller for our NPCs. Behaviour is determined using a heuristic to perform a greedy selection of actions."
/>
Each action computes:

- **EFactor**: effect on energy
- **PFactor**: effect on pleasantness

These influence the NPC’s mood, which updates after each action.

#### Mood and Personality in Action

- Personality traits determine an NPC’s desired emotional state.
- Actions impact their current mood.
- The **potential value** of an action is how close it brings the NPC to their desired mood.
- NPCs prefer actions with high potential value and may interrupt actions mid-way to switch to something better.

<br />

### Simulation Environment

A custom maze was built in Unity. Each NPC starts in a common area and tries to reach the exit, either alone or by collaborating with others. NPCs choose from the following actions:

- **Go To Node** - Move to a specific node in the maze. This will always be a node that has not been visited yet. Influenced by Conscientiousness.
- **Greet** - Greet another NPC. This gets the NPCs acquainted with one another, allowing them to perform other social actions. Influenced by Extroversion.
- **Follow** - Follow another NPC. This is influenced by Extroversion, Agreeableness, and perception of the other NPC.
- **Share** - The NPC can decide to tell others about where they have already explored. Influenced by Agreeableness.
- **Wait** - If an NPC notices that someone else if following them, they can choose to wait. Influenced by Agreeableness and Neuroticism.
- **Scan** - The NPC can decide to scan for maze nodes and other NPCs. Influenced by Conscientiousness.

<ImageGrid>
  <Image
    src="/npc-maze.png"
    alt="Maze Overview"
    width={500}
    captionText="Maze Overview"
  />
  <Image
    src="/maze-nodes.png"
    alt="Maze Nodes"
    width={500}
    captionText="Our maze, overlaid with labeled maze nodes. The blue-green numbered spheres show the location of all the maze nodes."
  />
</ImageGrid>
<ImageGrid>
  <Image
    src="/npc-closeup.png"
    alt="A closeup of an NPC in the maze"
    width={500}
    captionText="A closeup of an NPC in the maze"
  />
  <Image
    src="/maze-sim-ui.png"
    alt="Maze Simulation UI"
    width={500}
    captionText="A screen capture of the maze simulation, including the user
interface elements that help the viewer understand what is happening."
  />
</ImageGrid>

NPCs:

- Maintain a memory of visited nodes
- Have a perception score for each other NPC (defines how much they like or dislike the other NPC)
- Can forge on alone, share knowledge, follow others, or wait for companions

<br />

### Procedural Animation

Mood-driven facial expressions are rendered using blendshapes. The NPC’s mood coordinates on the circumplex graph determine which facial expressions are blended and displayed.

<ImageGrid>
  <Image
    src="/mood-graph.png"
    alt="Mood Graph with Emotions"
    width={500}
    captionText="Mood Graph with Emotions"
  />
  <Image
    src="/npc-facial-expressions.png"
    alt="Facial Expression Examples"
    width={800}
    captionText="Facial animation blendshapes were mapped to moods, and then the moods were mapped to positions on our mood graph. This shows the resulting facial animations as the current mood moves to different positions on the mood graph. From left to right: (1) medium energy and medium pleasantness (control), (2) medium energy and low pleasantness, (3) medium energy and high pleasantness, (4) low energy and medium pleasantness, (5) low energy and low pleasantness, (6) low energy and high pleasantness, (7) high energy and medium pleasantness, (8) high energy and low pleasantness, (9) high energy and high pleasantness."
  />
</ImageGrid>

This enables real-time visual feedback of internal emotional states without manual animation.

<br />

### Results

#### Emergent Behavior

100 iterations of the simulation showed clear correlations between personality traits and behavior choices. For example:

- NPCs high in **conscientiousness** explored more of the maze.
- NPCs high in **extraversion** were more likely to greet or follow others.
- **Neurotic** NPCs had stronger emotional fluctuations.

<ImageGrid>
  <Image
    src="/trait-action-correlation-table.png"
    alt="Trait Versus Action Correlation"
    width={500}
    captionText="The correlation between each personality trait and the go to
node, follow, share, and wait actions. The correlation value, r, is the
Pearson product-moment correlation coefficient."
  />
  <Image
    src="/trait-to-desired-mood-table.png"
    alt="Trait to Desired Mood Correlation Table"
    width={500}
    captionText="The correlation between each personality trait and the average
distance from the NPC’s current to desired moods. The correlation value,
r, is the Pearson product-moment correlation coefficient."
  />
</ImageGrid>

The results of the simulation were as expected, since I hand-configured each action to be more or less desirable for each personality trait. However, the real success is in the emergent behavior that was produced by small variations in personality. Even a small change in personality could lead to a completely different outcomes in terms of who finished first, who helped or avoided others, and so on.

In the future, I would like to explore ways to improve the decision-making algorithm. It worked fine in my small maze environment, but it can still likely be improved. For example, I think collaborating with a dev team that works on sports games could be a great way to improve the algorithm. NPCs in sports games have to make decisions about when to pass, shoot, or dribble, and they have to do it in real time.

#### Procedural Animation Evaluation

The facial animation system successfully reflected mood changes. NPCs showed more lifelike expressions, helping viewers intuitively understand their emotional state. The UI elements were also a success, and allowed us to see the changes in mood and personality in real time.

As a proof of concept, this procedural animation system worked very well. However, the quality of the facial animation could certaintly be enhanced by someone who is more skilled in animation. In the future, I would like to use a more sophisticated facial animation system—possibly involving animation handles and facial rigs.

<Image
  src="/maze-sim-ui-closeup.png"
  alt="A closeup of the maze simulation UI, showing the NPC status and face"
  width={300}
  captionText="A close-up view of the NPC status user interface elements,
including the view of each NPC’s face. This shows the procedural facial
animation for each NPC, which is determined by their mood."
/>

<br />

### Future Work

Ideas for future development include:

- Using more granular personality traits (facets)
- Expanding mood models
- Improving procedural animations for body language, not just facial expressions
- Testing in more complex or varied environments

<br />

### Conclusion

This thesis demonstrated that combining personality and mood models from psychology can dramatically improve the believability and behavior of NPCs. The integration of real-time emotion simulation and procedural facial animation creates characters that not only act differently but also feel emotionally alive—bringing us one step closer to the immersive realism often promised but rarely delivered in video games.

**Portfolio Impact**: This work showcases my ability to bridge academic research with practical game development, implement complex behavioral systems, and communicate technical concepts effectively. The statistical validation and real-world applications demonstrate both research rigor and industry relevance.
